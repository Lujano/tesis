\chapter{Introducción}
\label{capitulo1}
\lhead{Capítulo 1. \emph{Introducción}}

En los últimos años se han logrado avances importantes en el área de navegación y exploración con robots móviles, lo que ha permitido ampliar las aplicaciones de éstos en espacios áereos, terrestres y acuáticos en diversas disciplinas, facilitando la extracción de información de estos entornos incluso en lugares de difícil acceso.

En este sentido el Grupo de Investigación y Desarrollo en Mecatrónica de la USB \textit{(GIDM)} ha venido desarrollando un conjunto de proyectos relacionados con los sistemas de navegación de robots autónomos y de operación remota de éstos desde el año 2013, donde el área de odometría y SLAM se ha venido trabajando con profundo interés por ser fundamental en la recopilación de información de diferentes ambientes y por abrir la puerta a la automatización de la exploración y navegación de vehículos autónomos.

\section{Antecedentes}

En el \textit{GIDM} se han realizado grandes avances en el empleo de vehículos operados remotamente \textit{ROV} (del inglés: Remotely Operated Vehicles) y de vehículos autónomos submarinos \textit{AUV} (del inglés: Automated Underwater Vehicles) para actividades de investigación, exploración e inspección de ambientes no estructurados.

En este sentido, en el año \textit{Certad, N.} \cite{novel} propuso en el 2013 como proyecto de maestría, un algoritmo de localización y mapeo simultáneo para un vehículo terrestre de locomoción diferencial instrumentado con sensores exteroceptivos, realimentado por odometría, el cual utilizó Webots como herramienta de simulación y fue implementado utlizando Matlab.


\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{Antecedentes/Certad}
	\caption{Resultados de trayectoria y reconstrucción de mapas obtenidos en \cite{novel}}
	\label{imagen:Antecedentes/Certad}
\end{figure}

En el 2017, \textit{Gonzáles M.} \cite{manuel} desarrolló un sistema de reconstrucción de modelos de ambiente utilizando un sensor de Detección y Localización por Láser (LIDAR, del inglés: Laser Imaging Detection and Ranging). Esta implementación se realizó utilizando ROS como núcleo de control y procesamiento de datos y \textit{Cartographer} como herramienta de manejo de la localización y mapeo del prototipo empleado. Los modelos reconstruidos como el presentado en la figura \ref{imagen:Antecedentes/octomaps} se realizaron utilizando estructuras probabilísticas de ocupación llamadas \textit{octomaps}, las cuales permitieron la disminución del uso de recursos de memoria en la reconstrucción de grandes entornos.


\begin{figure}[H]
	\centering
	\includegraphics[width=0.3\textwidth]{Antecedentes/mapa2D}
	\includegraphics[width=0.3\textwidth]{Antecedentes/mapa2DReal}
	\caption{Resultados de trayectoria y reconstrucción de mapas obtenidos en \cite{manuel}. A la izquierda se presenta el mapa original obtenido y a la derecha se presenta superpuesto al diagrama del edificio real.}
	\label{imagen:Antecedentes/mapa2D}
\end{figure}


\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{Antecedentes/Octomaps}
	\caption{Reconstrucción en tres dimensiones utilizando octomaps obtenidos
		en  \cite{manuel}}
	\label{imagen:Antecedentes/octomaps}
\end{figure}

En 2018,  \textit{Morales F.} \cite{fabio} desarrolló un sistema de odometría basado en cámara monocular utilizando un método directo basado en optimización de Gauss-Newton para estimar el movimiento de la cámara. La figura \ref{imagen:Antecedentes/fabio} presenta los resultados obtenidos utilizando la secuencia freiburg2 xyz del banco de datos RGB-D SLAM Dataset and Benchmark, creado por Jürgen
Sturm de la Universidad Tecnológica de Múnich.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{Antecedentes/fabio}
	\caption{Gráficas X vs Y del movimiento de la cámara de la secuencia
		freiburg2 xyz. Izquierda: gráfica del movimiento real de la cámra en X y Y.
		Derecha: gráfica del movimiento estimado de la cámara en X y Y.}
	\label{imagen:Antecedentes/fabio}
\end{figure}

 En este sentido, se tienen proyectos como el presentado por \textit{Danilo, D.} \cite{danilo}, cuyo proyecto de grado consistió en el desarrollo en un sistema de operación remota para un prototipo de robot submarino (\textit{Poseibot}), con la finalidad de implementarlo en tareas de exploración. Con objetivos similares, \textit{Said, A.} \cite{said} basó su proyecto de grado en la instrumentación y control de un robot cuadricóptero volador(\textit{UAV}) diseñado y fabricado también como parte de dicho proyecto. Este prototipo se presenta en la figura \ref{imagen:said}.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{Antecedentes/said}
	\caption{Prototipo UAV desarrollado en  \cite{said}}
	\label{imagen:said}
\end{figure}

Adicional a estos prototipos,  el \textit{GIDM} cuentan con otras plataformas móviles como \textit{Roomba}, \textit{AmigoBot}, y un vehículo submarino OpenROV\footnote{ \url{https://www.openrov.com/products/openrov28/}}, el cual es un robot maniobrado remotamente de baja envergadura, diseñado especialmente operaciones de exploración y está dotado, entre otras cosas, con una cámara de video HD y una unidad de medición inercial.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{openrov}
	\caption{Robot móvil OpenROV}
	\label{imagen:openrov}
\end{figure}

Si bien se cuenta con un conjunto de plataformas robóticas adaptadas para tareas de exploración, hasta el momento los sistemas de navegación y mapeo empleados han estado basados en GPS y telémetro láser, pero aún no se ha concluido el desarrollo de sistemas basados en visión que permitan la navegación y mapeo. La presente investigación es la primera en abordar la tarea de la reconstrucción de la superficie recorrida haciendo uso únicamente de una cámara de vídeo, sensor presente en todas las plataformas robóticas antes mencionados.

\section{Justificación y planteamiento del problema}

El Grupo de Investigación y Desarrollo en Mecatrónica de la USB ha venido desarrollando un conjunto de proyectos relacionados con los sistemas de navegación de robots autónomos y de operación remota de estos. Actualmente cuentan con un vehículo submarino OpenROV 2.8 de operación remota (ROUV, por sus siglas en inglas - Remotely Operated Underwater Vehicle) el cual posee una IMU y tiene la capacidad de transmitir videos en alta definición. Es por ello que los trabajos más recientes de este grupo han estado enfocados al área de visión por computadora con la finalidad de mejorar el desempeño y las capacidades de los sistemas de control de vehículos como el OpenROV 2.8, y para realizar exploración submarina como reconstrucciones y muestreos de arrecifes, embarcaciones hundidas y fauna submarina. Entre estos trabajos se encuentra el proyecto de grado de Fabio Morales, en el cual se implementó un sistema de odometría visual para resolver el problema de SLAM en robots submarinos basado en una cámara monocular, y el proyecto de grado de  Armando Longart, en el cual se desarrollaron módulos de procesamiento de imágenes y video para aplicaciones subacuáticas.

Dichos trabajos permiten la posibilidad de ser integrados  y optimizados en un nuevo sistema de SLAM visual más robusto, y que además permita ser extendido para robots en diferentes entornos, automatizando la generación de las operaciones de mapeo y localización del vehículo.

\section{Objetivos}

\subsection{Objetivo General}

Analizar e implementar un sistema automatizado que permita la localización de un robot terrestre, aéreo o submarino, a través de la información capturada por una cámara monucular y una unidad de medición inercial, además de realizar un mapa de su entorno.

\subsection{Objetivos Específicos}

\begin{itemize}
	\item  Revisar la localización y mapeo simultáneo en robots móviles (aéreos, terrestres y submarinos) basados en cámara.
	\item Revisar los métodos de procesamiento de imágenes convenientes para los algoritmos de SLAM visual en función del entorno del robot móvil.
	\item Implementar un sistema de SLAM visual.
	\item Generar la posición, trayectoria del robot móvil y  un mapa 3D aproximado de su entorno.
\end{itemize}

\section{Estructura del trabajo}

El presente trabajo se encuentra estructurado en 7 capítulos. El \textit{\textbf{Capítulo 1}} describe el problema a resolver, y los antecedentes y objetivos del proyecto.

El estado del arte de la odometría y el SLAM visual inercial es detallado en el \textit{\textbf{Capítulo 2}} donde se presentan los trabajos recientes y avances importantes en esta área de investigación. Posteriormente , en base a las técnicas y algoritmos estudiados, se propone un esquema de odometría visual inercial.


El \textit{\textbf{Capítulo 3}} inicia una revisión teórica en la que se describe el modelo de la cámara utilizado, las transformaciones de cuerpo rígido, 
el funcionamiento de los algoritmos detectores, descriptores y emparejadores de características, el filtrado de correspondencias y los filtros de fusión inercial.

La metodología implementada en este trabajo se presenta en el \textit{\textbf{Capítulo 4}}, en donde se introducen los conceptos necesarios para su implementación.

Posteriormente, en el \textit{\textbf{Capítulo 5}} se presenta el desarrollo de un dataset local visual inercial. En este capítulo se expone el diseño del robot prototipo utilizado, así como también los componentes de hardware empleados y el diagrama del esquema de recopilación de datos implementados. Además se presenta la calibración de los sensores involucrados y los resultados obtenidos para la odometría del robot.

En el \textit{\textbf{Capítulo 6}} se presenta la implementación del esquema del sistema, en donde se presentan los resultados obtenidos por dos tipos de métodos diferentes a lo largo de varias secuencias de datos. También se incluye un análisis comparativo de los resultados.


Finalmente, en el \textit{\textbf{Capítulo 7}} se presentan las conclusiones derivadas del proyecto, además de propuestas sobre recomendaciones y posibles implementaciones que pueden aportar mejoras y/o permitir la continuación del desarrollo de investigación aquí descrito.
